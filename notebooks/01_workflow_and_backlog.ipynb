{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workflow & Backlog\n",
    "\n",
    "## Overview & Goals\n",
    "\n",
    "**Challenge:** Build a production-ready Retrieval-Augmented Generation (RAG) system for Deutsche Telekom that enables question-answering over internal publications and documents.\n",
    "\n",
    "**Goals:**\n",
    "- Efficiently index and retrieve relevant document chunks\n",
    "- Generate accurate, cited responses using retrieved context\n",
    "- Maintain traceability with publication IDs\n",
    "- Support enterprise requirements (security, monitoring, scalability)\n",
    "- Enable easy experimentation and iteration\n",
    "\n",
    "**Key Components:**\n",
    "- Document loading with metadata extraction\n",
    "- Metadata-aware chunking\n",
    "- Vector-based retrieval with optional reranking\n",
    "- LLM-based generation with citation\n",
    "- Structured logging and observability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Load and examine sample documents from the data folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path (notebooks/ is one level below project root)\n",
    "project_root = Path().resolve().parent\n",
    "if (project_root / \"config\").exists():\n",
    "    sys.path.insert(0, str(project_root))\n",
    "else:\n",
    "    # Try current directory if already at project root\n",
    "    if (Path().resolve() / \"config\").exists():\n",
    "        sys.path.insert(0, str(Path().resolve()))\n",
    "\n",
    "from data.loader import DocumentLoader\n",
    "from config import settings\n",
    "\n",
    "# Load a few sample documents\n",
    "loader = DocumentLoader(data_folder=settings.DATA_FOLDER)\n",
    "documents = loader.load_all_documents()\n",
    "\n",
    "print(f\"Total documents loaded: {len(documents)}\")\n",
    "print(f\"\\nSample documents:\")\n",
    "for i, doc in enumerate(documents[:3], 1):\n",
    "    pub_id = doc.metadata.get(\"publication_id\", \"unknown\")\n",
    "    word_count = doc.metadata.get(\"word_count\", len(doc.page_content.split()))\n",
    "    print(f\"\\n{i}. Publication ID: {pub_id}\")\n",
    "    print(f\"   Word count: {word_count}\")\n",
    "    print(f\"   Topics: {doc.metadata.get('topics', [])}\")\n",
    "    print(f\"   Preview: {doc.page_content[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word statistics across all documents\n",
    "if documents:\n",
    "    total_words = sum(doc.metadata.get(\"word_count\", 0) for doc in documents)\n",
    "    avg_words = total_words / len(documents) if documents else 0\n",
    "    \n",
    "    print(f\"\\nDocument Statistics:\")\n",
    "    print(f\"  Total documents: {len(documents)}\")\n",
    "    print(f\"  Total words: {total_words:,}\")\n",
    "    print(f\"  Average words per document: {avg_words:.0f}\")\n",
    "    print(f\"  Documents with topics: {sum(1 for d in documents if d.metadata.get('topics'))}\")\n",
    "    print(f\"  Documents with dates: {sum(1 for d in documents if d.metadata.get('mentioned_dates'))}\")\n",
    "    \n",
    "    # Count by topics\n",
    "    all_topics = []\n",
    "    for doc in documents:\n",
    "        all_topics.extend(doc.metadata.get(\"topics\", []))\n",
    "    \n",
    "    from collections import Counter\n",
    "    topic_counts = Counter(all_topics)\n",
    "    print(f\"\\nTopic distribution:\")\n",
    "    for topic, count in topic_counts.most_common():\n",
    "        print(f\"  {topic}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Workflow\n",
    "\n",
    "Index documents using the loader, chunker, and ChromaDB (in-memory for notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.chunking import MetadataAwareChunker\n",
    "from core.embeddings import get_embeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = get_embeddings()\n",
    "print(\"✓ Loaded embeddings model\")\n",
    "\n",
    "# Chunk documents with metadata\n",
    "chunker = MetadataAwareChunker(\n",
    "    chunk_size=settings.CHUNK_SIZE,\n",
    "    chunk_overlap=settings.CHUNK_OVERLAP\n",
    ")\n",
    "print(f\"✓ Initialized chunker (size={settings.CHUNK_SIZE}, overlap={settings.CHUNK_OVERLAP})\")\n",
    "\n",
    "# Chunk all documents\n",
    "all_chunks = []\n",
    "for doc in documents[:5]:  # Use first 5 docs for demo\n",
    "    source = doc.metadata.get(\"source\", \"Deutsche Telekom\")\n",
    "    doc_id = doc.metadata.get(\"publication_id\", doc.metadata.get(\"file_name\", \"unknown\"))\n",
    "    extra_metadata = {\n",
    "        k: v for k, v in doc.metadata.items()\n",
    "        if k not in [\"source\", \"publication_id\", \"file_name\"]\n",
    "    }\n",
    "    \n",
    "    chunks = chunker.chunk_with_metadata(\n",
    "        text=doc.page_content,\n",
    "        source=source,\n",
    "        doc_id=doc_id,\n",
    "        **extra_metadata\n",
    "    )\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(f\"✓ Created {len(all_chunks)} chunks from {min(5, len(documents))} documents\")\n",
    "print(f\"  Average chunks per document: {len(all_chunks) / min(5, len(documents)):.1f}\")\n",
    "\n",
    "# Show sample chunk metadata\n",
    "if all_chunks:\n",
    "    sample = all_chunks[0]\n",
    "    print(f\"\\nSample chunk metadata:\")\n",
    "    print(f\"  chunk_id: {sample.metadata.get('chunk_id')}\")\n",
    "    print(f\"  doc_id: {sample.metadata.get('doc_id')}\")\n",
    "    print(f\"  chunk_index: {sample.metadata.get('chunk_index')}\")\n",
    "    print(f\"  total_chunks: {sample.metadata.get('total_chunks')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in-memory ChromaDB (no persistence for notebook)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "print(f\"✓ Indexed {len(all_chunks)} chunks into ChromaDB\")\n",
    "print(f\"  Vector dimensions: {len(embeddings.embed_query('test'))}\")\n",
    "print(f\"  Collection count: {vectordb._collection.count() if hasattr(vectordb, '_collection') else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Demo\n",
    "\n",
    "Run queries and examine retrieved sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.retrieval import AdvancedRetriever\n",
    "\n",
    "# Create retriever (no reranker for CPU-only demo)\n",
    "retriever = AdvancedRetriever(vectordb=vectordb, reranker_model=None)\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"What is 5G?\",\n",
    "    \"Tell me about security\",\n",
    "    \"Partnership information\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = retriever.retrieve(query=query, top_k=3)\n",
    "    \n",
    "    print(f\"Retrieved {len(results)} documents:\\n\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        pub_id = doc.metadata.get(\"publication_id\", doc.metadata.get(\"doc_id\", \"unknown\"))\n",
    "        chunk_idx = doc.metadata.get(\"chunk_index\", \"N/A\")\n",
    "        print(f\"{i}. [Publication: {pub_id}, Chunk: {chunk_idx}]\")\n",
    "        print(f\"   {doc.page_content[:150]}...\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Demo\n",
    "\n",
    "Build prompts and generate responses. Using mock model for CPU-only execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.prompt_manager import PromptManager\n",
    "\n",
    "prompt_manager = PromptManager()\n",
    "\n",
    "# Build RAG prompt with retrieved context\n",
    "query = \"What services does Deutsche Telekom offer?\"\n",
    "retrieved_docs = retriever.retrieve(query=query, top_k=2)\n",
    "\n",
    "prompt = prompt_manager.build_rag_prompt(\n",
    "    query=query,\n",
    "    context_docs=retrieved_docs,\n",
    "    chat_history=None\n",
    ")\n",
    "\n",
    "print(\"Generated Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(prompt[:1000])  # Show first 1000 chars\n",
    "print(\"...\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPrompt length: {len(prompt)} characters\")\n",
    "print(f\"Context documents used: {len(retrieved_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock generation for CPU-only demo (no actual LLM call)\n",
    "# In production, this would call generate_response() with real model\n",
    "\n",
    "print(\"Mock Generation Response:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract publication IDs from sources\n",
    "publication_ids = []\n",
    "for doc in retrieved_docs:\n",
    "    pub_id = doc.metadata.get(\"publication_id\", doc.metadata.get(\"doc_id\", \"unknown\"))\n",
    "    if pub_id not in publication_ids:\n",
    "        publication_ids.append(pub_id)\n",
    "\n",
    "# Simulate response (in real system, this comes from LLM)\n",
    "mock_response = f\"\"\"Based on the retrieved documents, Deutsche Telekom offers various telecommunications services including 5G network infrastructure, secure cloud solutions, and enterprise partnerships. The company focuses on expanding coverage and providing reliable connectivity services.\n",
    "\n",
    "Sources: {', '.join(publication_ids)}\"\"\"\n",
    "\n",
    "print(mock_response)\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n[Note: This is a mock response. In production, use generate_response() with loaded model]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observability\n",
    "\n",
    "Show structured logging output example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.logging import StructuredLogger\n",
    "import json\n",
    "\n",
    "# Create logger\n",
    "logger = StructuredLogger(\"notebook_demo\", log_dir=\"/tmp/notebook_logs\")\n",
    "\n",
    "# Log a sample query\n",
    "sample_docs = retrieved_docs[:2] if retrieved_docs else []\n",
    "logger.log_query(\n",
    "    query=\"What services does Deutsche Telekom offer?\",\n",
    "    retrieved_docs=sample_docs,\n",
    "    response_time=1.23,\n",
    "    user_id=\"notebook_user\"\n",
    ")\n",
    "\n",
    "# Show what was logged (read the JSON line from the log file)\n",
    "import os\n",
    "log_file = \"/tmp/notebook_logs/notebook_demo.jsonl\"\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        log_line = f.readlines()[-1] if f.readlines() else None\n",
    "        if log_line:\n",
    "            log_data = json.loads(log_line)\n",
    "            print(\"Sample Structured Log Entry:\")\n",
    "            print(\"=\"*80)\n",
    "            print(json.dumps(log_data, indent=2))\n",
    "            print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Sample log entry structure:\")\n",
    "    sample_log = {\n",
    "        \"timestamp\": \"2024-01-01T12:00:00Z\",\n",
    "        \"level\": \"INFO\",\n",
    "        \"logger\": \"notebook_demo\",\n",
    "        \"message\": \"Query processed\",\n",
    "        \"event_type\": \"query\",\n",
    "        \"query\": \"What services does Deutsche Telekom offer?\",\n",
    "        \"num_documents\": 2,\n",
    "        \"response_time_seconds\": 1.23,\n",
    "        \"user_id\": \"notebook_user\",\n",
    "        \"document_ids\": [\"doc_1\", \"doc_2\"]\n",
    "    }\n",
    "    print(json.dumps(sample_log, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backlog of Ideas\n",
    "\n",
    "Future enhancements and experiments for the RAG system:\n",
    "\n",
    "### Retrieval & Ranking\n",
    "- **Switch to better embeddings**: Evaluate and switch to `intfloat/e5-large-v2` or `bge-large-en-v1.5` embeddings; compare recall@k metrics against current `all-MiniLM-L6-v2`\n",
    "- **Max Marginal Relevance (MMR)**: Implement diversity-based retrieval to reduce redundant results\n",
    "- **Hybrid Retrieval**: Combine sparse+dense retrieval (BM25 + vector search) for improved recall\n",
    "- **Reranker A/B Testing**: Compare `cross-encoder/ms-marco-MiniLM-L-6-v2` vs `bge-reranker-large`; log reranking scores for analysis\n",
    "\n",
    "### Provenance & Citations\n",
    "- **Normalized chunk IDs + provenance**: Store byte spans and filenames for each chunk\n",
    "- **Inline snippet highlights**: Show highlighted source snippets in responses with exact character spans\n",
    "\n",
    "### Response Quality & Guardrails\n",
    "- **Response guardrails**: \n",
    "  - Require citations for factual statements\n",
    "  - Refusal mechanism when confidence score is below threshold\n",
    "  - Log confidence scores for monitoring\n",
    "- **Prompt compression (LLMLingua)**: Compress long context for better efficiency while preserving key information\n",
    "\n",
    "### Evaluation & Quality\n",
    "- **Eval harness**: Implement RAGAS (Retrieval-Augmented Generation Assessment) metrics:\n",
    "  - Context Precision\n",
    "  - Context Recall  \n",
    "  - Faithfulness\n",
    "  - Answer Relevancy\n",
    "- **Hand-curated Q/A set**: Create golden dataset over the 250 documents for regression testing\n",
    "- **Nightly CI evaluation**: Run RAGAS metrics in CI pipeline on golden set to detect regressions\n",
    "\n",
    "### Performance & Optimization\n",
    "- **Caching**: Implement Redis/SQLite caching layer keyed by `(normalized_query, embedding_hash, index_version)` to avoid redundant retrievals and generations\n",
    "- **Vector DB swaps**: Support FAISS index via Chroma settings; create plug-in layer for Milvus/PGVector backends\n",
    "- **Async Processing**: Use async/await for concurrent operations\n",
    "\n",
    "### User Experience\n",
    "- **Cancellation support**: Allow users to cancel long-running queries\n",
    "- **Queue limit**: Implement request queue limits to prevent overload\n",
    "\n",
    "### Security & Authentication\n",
    "- **FastAPI authentication**: Implement API key or OAuth2 authentication\n",
    "- **Rate limiting**: Add per-user/IP rate limiting to prevent abuse\n",
    "\n",
    "### Security & Authentication\n",
    "- **FastAPI authentication**: Implement API key or OAuth2 authentication\n",
    "- **Rate limiting**: Add per-user/IP rate limiting to prevent abuse\n",
    "\n",
    "### Multilingual & Internationalization\n",
    "- **Multilingual Support**: Support documents in multiple languages with language detection\n",
    "- **Cross-lingual Retrieval**: Retrieve relevant content even when query language differs from document language\n",
    "\n",
    "### Data Management & Deployment\n",
    "\n",
    "- **Externalize data folder**: Inject the data/ directory at runtime instead of committing it to Git:\n",
    "  - Mount it as a Docker/K8s volume or download from secure storage (S3, Azure Blob, etc.) during startup.\n",
    "  - Add checksum validation and update scripts to ensure dataset integrity across environments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
